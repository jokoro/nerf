{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVQDM3eFTYJ3"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = '/'\n",
        "# uncomment for gcp:\n",
        "# %pdb off\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "import os\n",
        "requirements_path = os.path.join(ROOT_PATH, 'requirements.txt')\n",
        "os.system(f'pip install -r {requirements_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3D-fEUtTYKD"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLsqkJTkTYKH"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from typing import *\n",
        "\n",
        "import cv2\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "\n",
        "import wandb\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import einops\n",
        "import ipdb\n",
        "from math import ceil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya0v18TggjMu"
      },
      "source": [
        "# Declare constants and load Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjPTrG6_TYKO"
      },
      "outputs": [],
      "source": [
        "NAME = 'bedroom'\n",
        "NAME = 'forest1'\n",
        "NAME = 'forest2'\n",
        "NAME = 'sidewalk'\n",
        "NAME = 'study'\n",
        "NAME = 'kitchen'\n",
        "NAME = 'bottle'\n",
        "NAME = 'apples'\n",
        "NAME = 'sourcream'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1oA752D5TYKP",
        "outputId": "39dd9cf5-8f40-4c98-9005-f5b6fb834d20"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SPARSE_PATH = os.path.join(ROOT_PATH, f'colmap/{NAME}/sparse')\n",
        "IMG_PATH = os.path.join(ROOT_PATH, f'colmap/{NAME}/images')\n",
        "IMG_PATH.mkdir(exist_ok=True)\n",
        "SEED = 0\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE\n",
        "# Sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bsVjq9ATYKP"
      },
      "outputs": [],
      "source": [
        "# cap = cv2.VideoCapture(f'videos/{name}.MOV')\n",
        "\n",
        "# frame_no = 0\n",
        "# every_n_frames = 10\n",
        "\n",
        "# while cap.isOpened():\n",
        "#     ret, frame = cap.read()\n",
        "\n",
        "#     if frame_no % every_n_frames == 0:\n",
        "#         target = imgpath.joinpath(f'{frame_no:06d}.jpg').as_posix()\n",
        "#         cv2.imwrite(target, frame)\n",
        "\n",
        "#     frame_no += 1\n",
        "#     if not ret: break\n",
        "\n",
        "# cap.release()\n",
        "# print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRz-ONlMTYKQ"
      },
      "source": [
        "# Camera class and dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkFz-9tjTYKQ"
      },
      "outputs": [],
      "source": [
        "# initialize camera objects (for now only one)\n",
        "\n",
        "class Camera:\n",
        "    def __init__(self, camera_id, model, width, height, params):\n",
        "        self.camera_id = camera_id\n",
        "        self.model = model\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.params = params\n",
        "        self.K = self._get_K()                  # size: 3 x 3\n",
        "        self.K_inv = self.K.inverse()           # size: 3 x 3\n",
        "        self.xy_pairs = self._get_xy_pairs()    # size: H*W, H*W\n",
        "        self.d_camera = self._get_d()           # size: H*W x 3\n",
        "\n",
        "    def _get_K(self):\n",
        "        if self.model == 'PINHOLE':\n",
        "            fx, fy, cx, cy = self.params\n",
        "            K = torch.tensor([\n",
        "                [fx, 0,  cx],\n",
        "                [0,  fy, cy],\n",
        "                [0,  0,  1 ],\n",
        "            ]).to(DEVICE)\n",
        "        elif self.model == 'SIMPLE_PINHOLE':\n",
        "            f, cx, cy = self.params\n",
        "            K = torch.tensor([\n",
        "                [f, 0, cx],\n",
        "                [0, f, cy],\n",
        "                [0, 0, 1 ],\n",
        "            ]).to(DEVICE)\n",
        "        return K\n",
        "\n",
        "    def _get_xy_pairs(self):\n",
        "        y, x = torch.unravel_index(\n",
        "            torch.arange(self.height * self.width).to(DEVICE),\n",
        "            (self.height, self.width),\n",
        "        )\n",
        "        return x, y\n",
        "\n",
        "    def _get_d(self):\n",
        "        x, y = self.xy_pairs\n",
        "        x = x.unsqueeze(0)                  # size: 1 x HW\n",
        "        y = y.unsqueeze(0)                  # size: 1 x HW\n",
        "\n",
        "        x_y_1 = torch.cat(\n",
        "            (x, y, torch.ones_like(x).to(DEVICE))\n",
        "        ).float().to(DEVICE)                # size: 3 x HW\n",
        "        d = self.K_inv @ x_y_1              # size: (3 x 3) @ (3 x HW) = 3 x HW\n",
        "        d = (d / d.norm(dim=0)).T           # size: HW x 3\n",
        "\n",
        "        return d\n",
        "\n",
        "\n",
        "def get_cameras():\n",
        "    camera_file_path = os.path.join(ROOT_PATH, f'colmap/{NAME}/sparse/cameras.txt')\n",
        "\n",
        "    with open(camera_file_path) as file:\n",
        "        camera_lines = file.readlines()[3:]\n",
        "\n",
        "    cameras = {}\n",
        "    for camera_line in camera_lines:\n",
        "        (camera_id, model, width, height, *params) = camera_line.strip('\\n').split()\n",
        "        camera_id, width, height = (int(s) for s in (camera_id, width, height))\n",
        "        params = [float(s) for s in params]\n",
        "        camera = Camera(camera_id, model, width, height, params)\n",
        "        cameras[camera_id] = camera\n",
        "\n",
        "    return cameras\n",
        "\n",
        "cameras: Dict[int, Camera] = get_cameras()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7ZYUw0JTYKR"
      },
      "source": [
        "# ImagePose class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgz6ZZkITYKV"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ImagePose:\n",
        "    def __init__(self, image_id, qw, qx, qy, qz, tx, ty, tz, camera_id, name):\n",
        "        self.image_id = image_id\n",
        "        self.r = self._quaternions_to_matrix(qw, qx, qy, qz)\n",
        "        self.t = torch.tensor([tx, ty, tz]).to(DEVICE)\n",
        "        self.camera_id = camera_id\n",
        "        self.name = name\n",
        "        self.image = self._imgfile_to_tensor()\n",
        "\n",
        "    def _quaternions_to_matrix(self, qw, qx, qy, qz):\n",
        "        # r = Rotation.from_quat([qw, qx, qy, qz])\n",
        "        # r = torch.tensor(R.as_matrix()).to(DEVICE)\n",
        "\n",
        "        r = torch.tensor([\n",
        "            [1 - 2 * (qy * qy + qz * qz),   2 * (qx * qy - qz * qw),        2 * (qx * qz + qy * qw)],\n",
        "            [2 * (qx * qy + qz * qw),       1 - 2 * (qx * qx + qz * qz),    2 * (qy * qz - qx * qw)],\n",
        "            [2 * (qx * qz - qy * qw),       2 * (qy * qz + qx * qw),        1 - 2 * (qx * qx + qy * qy)],\n",
        "        ]).to(DEVICE)\n",
        "\n",
        "        return r\n",
        "\n",
        "    def _imgfile_to_tensor(self):\n",
        "        path = os.path.join(IMG_PATH, self.name)\n",
        "        image = Image.open(path)\n",
        "        image_tensor = F.to_tensor(image).to(DEVICE)\n",
        "        return image_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FDlUngsTYKV"
      },
      "source": [
        "# Config and wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD-QgPt4TYKV"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'name': 'initial-run-aws',\n",
        "    'batch_size': 4096,\n",
        "    'initial_lr': 5e-4,\n",
        "    'final_lr': 5e-5,\n",
        "    'num_iter': int(100e3),\n",
        "\n",
        "    # these two probably shouldn't change.\n",
        "    # consider removing from config\n",
        "    'tn': 0,\n",
        "    'tf': 1,\n",
        "\n",
        "    'Nc': 64,\n",
        "    'Nf': 128,\n",
        "    'Lx': 10,\n",
        "    'Ld': 4,\n",
        "\n",
        "    'eps': 1.e-7,\n",
        "}\n",
        "B, TN, TF, NC, NF = config['batch_size'], config['tn'], config['tf'], config['Nc'], config['Nf']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gvHF112TYKW"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"nerf.ipynb\"\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM14bofCTYKX"
      },
      "outputs": [],
      "source": [
        "# run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "LwY4YV1uTYKX",
        "outputId": "9e7709d8-9d90-4968-9ad4-ff2796dfb6c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find nerf.ipynb.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjay-okoro\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240507_012525-1x6v6j70</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jay-okoro/nerf/runs/1x6v6j70' target=\"_blank\">initial-run-colab</a></strong> to <a href='https://wandb.ai/jay-okoro/nerf' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jay-okoro/nerf' target=\"_blank\">https://wandb.ai/jay-okoro/nerf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jay-okoro/nerf/runs/1x6v6j70' target=\"_blank\">https://wandb.ai/jay-okoro/nerf/runs/1x6v6j70</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    project='nerf',\n",
        "    name=config['name'],\n",
        "    reinit=True,\n",
        "    config=config,\n",
        "    # id=None, # id of run to resume\n",
        "    # resume='must', # if want to resume, comment reinit\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X2R9d6FPTYKY",
        "outputId": "db5fc46f-e429-46c6-e478-53a462dbebca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1x6v6j70'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run.id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBSTVy2OTYKY"
      },
      "source": [
        "# Create dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7pzW_gxTYKY"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Collects 3D points from points_path and pairs it with various viewing\n",
        "directions and cooresponding colors from those directions using images_path.\n",
        "Output format: (x, d), c\n",
        "    where   x is tensor of 3D location          size: 3 or B x 3\n",
        "            d is tensor of viewing direction    size: 3 or B x 3\n",
        "            c is tensor of RGB value            size: 3 or B x 3\n",
        "'''\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, images_path=os.path.join(SPARSE_PATH, 'images.txt')):\n",
        "        # values for NDC projection\n",
        "        # paper uses [-cx, -cy, f] b/c they use (y up, z into camera)\n",
        "        # but we use [cx, cy, f] b/c we use (y down, z out of camera)\n",
        "        # b/c of colmap, but also I prefer colmap's way and would use it again\n",
        "        # pose dependent: 1 -> pose.camera_id\n",
        "        f, cx, cy = cameras[1].params  # cx, cy = W/2, H/2\n",
        "        self.x, self.y = cameras[1].xy_pairs          # size: HW\n",
        "        self.d_camera = cameras[1].d_camera           # size: HW x 3\n",
        "        self.num_pixels = cameras[1].height * cameras[1].width\n",
        "\n",
        "        self.scalar = torch.tensor([f/cx, f/cy, 1]).to(DEVICE) #  = f / [cx, cy, f]\n",
        "        self.two_f = 2 * f\n",
        "\n",
        "        with open(images_path) as file:\n",
        "            self.image_lines = file.readlines()[4::2]\n",
        "\n",
        "    # converts line in image.txt to ImagePose object\n",
        "    def _get_image_pose(self, image_line):\n",
        "        (image_id, qw, qx, qy, qz, tx, ty, tz, camera_id, name\n",
        "        ) = image_line.strip('\\n').split()\n",
        "\n",
        "        image_id, camera_id = int(image_id), int(camera_id)\n",
        "        (qw, qx, qy, qz, tx, ty, tz,\n",
        "        ) = (float(s) for s in (qw, qx, qy, qz, tx, ty, tz))\n",
        "\n",
        "        pose = ImagePose(image_id, qw, qx, qy, qz, tx, ty, tz, camera_id, name)\n",
        "\n",
        "        return pose\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_lines * self.num_pixels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_idx = idx // self.num_pixels\n",
        "        pixel_idx = idx % self.num_pixels\n",
        "\n",
        "        image_line = self.image_lines[image_idx]\n",
        "        pose = self._get_image_pose(image_line)\n",
        "\n",
        "        # find origin of camera and directions from origin\n",
        "        # to pixels in world coordinates and get c (colors)\n",
        "        r, t = pose.r, pose.t.unsqueeze(0)              # size: 3x3, 1x3\n",
        "        o = -t @ r          # -r.T @ t                  # size: 1 x 3\n",
        "        d = self.d_camera @ r    #  r.T @ d_camera      # size: HW x 3\n",
        "        c = pose.image[:, self.y, self.x].T                       # size: HW x 3\n",
        "\n",
        "        # NDC projection\n",
        "        #   links to understand NDC better:\n",
        "        #   https://www.youtube.com/watch?v=U0_ONQQ5ZNM\n",
        "        #   https://yconquesty.github.io/blog/ml/nerf/nerf_ndc.html#analysis\n",
        "        o = o / o[:,2:3]\n",
        "        d = d / d[:,2:3]\n",
        "\n",
        "        o[:,2] += self.two_f\n",
        "        d -= o\n",
        "\n",
        "        o *= self.scalar\n",
        "        d *= self.scalar\n",
        "\n",
        "        # pick the pixel\n",
        "        d = d[pixel_idx]                               # size: 3\n",
        "        c = c[pixel_idx]                               # size: 3\n",
        "\n",
        "        # resize to use broadcasting for stratified\n",
        "        # sampling at training/inference stage.\n",
        "        d = d.unsqueeze(0)                            # size: 1x3\n",
        "\n",
        "        return o, d, c                                # size: 1x3, 1x3, 3\n",
        "\n",
        "trainset = TrainDataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9bUuCSFjpjJ"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "num_epochs = int(ceil(config['num_iter'] * config['batch_size'] / len(trainloader)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4k4hUg8TYKb"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5p1YmTzTYKf"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module): # tested\n",
        "    def __init__(self, in_feat, out_feat, activation=nn.ReLU()):\n",
        "        super().__init__()\n",
        "        self.f = nn.Sequential(\n",
        "            nn.Linear(in_feat, out_feat),\n",
        "            activation\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.f(x)\n",
        "\n",
        "class PositionalEncoding(nn.Module): # tested\n",
        "\n",
        "    def __init__(self, L):\n",
        "        super().__init__()\n",
        "\n",
        "        self.L = L\n",
        "        self.omega = 2**torch.arange(0, L, 1/2).int().to(DEVICE) * torch.pi\n",
        "\n",
        "    def forward(self, x):                                       # size: BxNx3\n",
        "        gamma = x.unsqueeze(-1) * self.omega                    # size: (BxNx3x1) * (2L) -> BxNx3x2L\n",
        "        gamma = einops.rearrange([torch.sin(gamma[...,::2]).to(DEVICE),\n",
        "                                  torch.cos(gamma[...,1::2]).to(DEVICE)],\n",
        "                                 't b n h w -> b n h (w t)').to(DEVICE)\n",
        "        gamma = gamma.flatten(-2)                               # size: BxNx3x2L = BxNx6L\n",
        "        return gamma\n",
        "\n",
        "class Nerf(nn.Module): # tested\n",
        "    def __init__(self, Lx, Ld):\n",
        "        super().__init__()\n",
        "        self.pos_enc_x = PositionalEncoding(Lx)\n",
        "        self.pos_enc_d = PositionalEncoding(Ld)\n",
        "\n",
        "        self.bfr_x_res = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            MLP(Lx*6,256),\n",
        "            MLP(256,256),\n",
        "            MLP(256,256),\n",
        "            MLP(256,256),\n",
        "            MLP(256,256),\n",
        "        )\n",
        "        self.bfr_d_in = nn.Sequential(\n",
        "            MLP(256+Lx*6,256),\n",
        "            MLP(256,256),\n",
        "            MLP(256,256),\n",
        "            MLP(256,257,nn.Identity()),\n",
        "        )\n",
        "        self.aft_d_in = nn.Sequential(\n",
        "            MLP(256+Ld*6,128),\n",
        "            MLP(128,3,nn.Sigmoid()),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, d):                            #   size: BxNx3, BxNx3\n",
        "        gamma_x = self.pos_enc_x(x)                     #   size: BxNx6Lx\n",
        "        out = self.bfr_x_res(gamma_x)                   #   size: BxNx256\n",
        "        out = torch.cat((out, gamma_x), -1)             #   size: BxNx(256+6Lx)\n",
        "        out = self.bfr_d_in(out)                        #   size: BxNx257\n",
        "        sig, out = out[:,:,0:1], out[:,:,1:]            #   size: BxNx1, BxNx256\n",
        "        gamma_d = self.pos_enc_d(d)                     #   size: BxNx6Ld\n",
        "        out = torch.cat((out, gamma_d), -1)             #   size: BxNx(256+6Ld)\n",
        "        rgb = self.aft_d_in(out)                        #   size: BxNx3\n",
        "\n",
        "        sig += torch.randn_like(sig).to(DEVICE) # paper says this is helpful for real scenes\n",
        "        sig = sig.relu()\n",
        "\n",
        "        return rgb, sig                             #   size: BxNx3, BxNx1\n",
        "\n",
        "model = Nerf(\n",
        "    config['Lx'],\n",
        "    config['Ld']\n",
        ").to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C9_R0xkTYKh"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9ia_N6ATYKi"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss(reduction='sum')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCXKgqPETYKj"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-0CwCUGTYKk"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=config['initial_lr'], eps=config['eps'])\n",
        "gamma = - (np.log(config['final_lr']) - np.log(config['initial_lr'])) / num_epochs\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO8AYcRzTYKk"
      },
      "source": [
        "# Train Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def color_weights_and_t_i(\n",
        "    tn: float,\n",
        "    tf: float,\n",
        "    N: int,\n",
        "    i_random: Tensor,\n",
        "    o: Tensor,\n",
        "    d: Tensor,\n",
        "    model: Nerf,\n",
        "    i_random_cat: Tensor = None\n",
        "):\n",
        "    if i_random_cat is not None:\n",
        "        # concat fine and coarse pts using t parameter\n",
        "        i_random = torch.cat((i_random, i_random_cat), -2)              # size: cat((BxNfx1),(Bx[Nc+1]x1), -2) -> Bx(Nf+Nc+1=N+1)x1\n",
        "        i_random = i_random.sort(-2)[0]\n",
        "\n",
        "    t_i = tn + i_random * (tf - tn) / N                                 # size: Bx(N+1)x1: (N = Nc if i_random_cat is None else N = Nf + Nc)\n",
        "    delta_i = (t_i.roll(-1, -2) - t_i)[:,:-1]                           # size: ((Bx[N+1]x1) - (Bx[N+1]x1))[:,:-1] -> BxNx1\n",
        "\n",
        "    x = o + t_i[:,:-1] * d # in NDC coords :)                           # size: (Bx1x3) + (BxNx1) * (Bx1x3) -> BxNx3\n",
        "    d = d.tile((1, x.shape[-2], 1))                                     # size: BxNx3\n",
        "\n",
        "    c_i, sigma_i = model(x, d)                                          # size: input: BxNx3, Bx3 | output: BxNx3, BxNx1\n",
        "    c_i: Tuple = c_i\n",
        "    sigma_i: Tuple = sigma_i\n",
        "\n",
        "    neg_sig_dlt_i: Tensor = -sigma_i * delta_i  # [a,  b,  ..., 0]      # size: (B x N x 1) * (B x N x 1) -> B x N x 1\n",
        "    neg_sig_dlt_im1 = neg_sig_dlt_i.roll(1, -2) # [0,  a,  b, ...]      # size: B x N x 1\n",
        "    T_i = torch.exp(neg_sig_dlt_im1.cumsum(-2)) # [1, eA, eB, ...]      # size: B x N x 1\n",
        "\n",
        "    w = T_i * (1 - torch.exp(neg_sig_dlt_i))                            # size: (BxNx1) * (BxNx1) -> BxNx1\n",
        "    c = (w * c_i).sum(-2)                                               # size: ((BxNx1) * (BxNx3) -> BxNx3).sum(-2) -> Bx3\n",
        "\n",
        "    return w, c\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtrZosEsTYKl"
      },
      "outputs": [],
      "source": [
        "w_hat_cum_mask = torch.ones(B, config['Nc'], 1).to(DEVICE)\n",
        "w_hat_cum_mask[:,0] = 0\n",
        "\n",
        "def get_i_fine(\n",
        "    w: Tensor,\n",
        "    Nf: int,\n",
        "    i: Tensor\n",
        "):\n",
        "    w_hat = w / w.sum(-2, True)                                                     # size: (BxNcx1) / ((BxNcx1).sum(-2, True) -> Bx1x1) -> BxNcx1\n",
        "    w_hat_cum = w_hat.cumsum(-2)                                                    # size: BxNcx1\n",
        "\n",
        "    u = torch.rand(B, 1, Nf).to(DEVICE)                                             # size: Bx1xNf\n",
        "    q = (u > w_hat_cum).sum(-2).flatten() # 0≤u≤w0: [F,F,F,...].sum: idx=0          # size: (((Bx1xNf) > (BxNcx1) -> BxNcxNf).sum(-2) -> (BxNf)) -> B*Nf\n",
        "    p, r = torch.unravel_index(torch.arange(B * Nf).to(DEVICE), (B, Nf))            # size: B*Nf, B*Nf\n",
        "\n",
        "    # inverse transform sampling (u > w_hat)\n",
        "    w_hat_cum = w_hat_cum.roll(1, -2) * w_hat_cum_mask\n",
        "    i_fine = ((u[p, :, r] - w_hat_cum[p, q]) / w_hat[p, q] + i[q])                  # size:\n",
        "                                                                                    # ( (Bx1xNf)  [(B*Nf),:,(B*Nf)]\n",
        "                                                                                    # - (BxNcx1)  [(B*Nf),(B*Nf)] )\n",
        "                                                                                    # / (BxNcx1)  [(B*Nf),(B*Nf)]\n",
        "                                                                                    # + (Ncx1)    [(B*Nf)]\n",
        "                                                                                    # -> B*Nfx1\n",
        "    i_fine = i_fine.view(B, Nf, 1)                                                  # size: BxNfx1\n",
        "\n",
        "    return i_fine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCxzdG-nTYKn"
      },
      "outputs": [],
      "source": [
        "def train(model, trainloader):\n",
        "    torch.manual_seed(SEED)\n",
        "\n",
        "    # t: NDC coords for ray parameter\n",
        "    # Nc: num bins along ray at first\n",
        "    # Nf: num new samples based on Nc dist.\n",
        "    i = torch.arange(float(NC+1), requires_grad=True).to(DEVICE).unsqueeze(-1)      # size: [Nc+1]x1\n",
        "    for epoch in tqdm(range(num_epochs), desc='epochs'):\n",
        "        for o, d, c in tqdm(trainloader, desc='minibatches', leave=False):          # size: Bx1x3, Bx1x3, Bx3\n",
        "            optimizer.zero_grad()\n",
        "            b = o.shape[0] # might change in last batch\n",
        "\n",
        "            # get coarse colors\n",
        "            i_coarse = i + torch.rand(b, NC+1, 1).to(DEVICE)                        # size: ([Nc+1]x1) + (Bx[Nc+1]x1) -> Bx[Nc+1]x1\n",
        "            w_coarse, c_coarse = color_weights_and_t_i(TN, TF, NC,\n",
        "                                                        i_coarse,\n",
        "                                                        o, d, model)                # Bx3, BxNcx1\n",
        "\n",
        "            # get fine colors\n",
        "            i_fine = get_i_fine(w_coarse, NF, i)                                    # size: BxNcx1\n",
        "            w_fine, c_fine = color_weights_and_t_i(TN, TF, NF, i_fine,\n",
        "                                                    o, d, model, i_coarse)          # size: Bx3, BxNcx1\n",
        "\n",
        "\n",
        "            loss: Tensor = criterion(c_coarse, c) + criterion(c_fine, c)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            # not logging accuracy b/c continuous values\n",
        "            # may be close but will rarely equal each other\n",
        "            wandb.log({'loss': loss})\n",
        "            torch.cuda.empty_cache()\n",
        "        scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iy7JUtF-rBHU"
      },
      "outputs": [],
      "source": [
        "# Train!\n",
        "train(model, trainloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSyM9LWCTYKo"
      },
      "outputs": [],
      "source": [
        "model_state_dict_path = os.path.join(ROOT_PATH, \"model_state_dict.pth\")\n",
        "torch.save(model.state_dict(), model_state_dict_path)\n",
        "wandb.save(model_state_dict_path)\n",
        "print(\"Model saved to Weights and Biases!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgCEGcKKTYKo"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0326e5002938470ca73163244c9836e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14992f4ab32b4ff1a990167cdc901ed0",
            "placeholder": "​",
            "style": "IPY_MODEL_5132eda4331d4f81a8c7104c1dac3f32",
            "value": " 0/1 [00:00&lt;?, ?it/s]"
          }
        },
        "0862e6d64c5046eeba6889937d3aa563": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14992f4ab32b4ff1a990167cdc901ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23687ddafaf84391aeca4b9f8ee6ac2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d87f2ea8b5a149bd8d00007b9bc454ef",
            "placeholder": "​",
            "style": "IPY_MODEL_9029ee82df314328a22b647cf40a1bc4",
            "value": "epochs:   0%"
          }
        },
        "32451ed3a368460196b16a0ff4a6e382": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e43337284943bb8284a61ae53516cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d71c7e21927c4d4bae8850142bfa57c1",
              "IPY_MODEL_67e04070004b4688a413f73f672ba6da",
              "IPY_MODEL_d6eed77f57a64b2eb748976eaa87ea43"
            ],
            "layout": "IPY_MODEL_77ccd734cc3e44f6bc0e2e17d2bb9ec8"
          }
        },
        "5132eda4331d4f81a8c7104c1dac3f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a9122fc5df44677a8ab8ea3d861c11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23687ddafaf84391aeca4b9f8ee6ac2d",
              "IPY_MODEL_c14f89939716435f9a5f5532c287d84b",
              "IPY_MODEL_0326e5002938470ca73163244c9836e7"
            ],
            "layout": "IPY_MODEL_32451ed3a368460196b16a0ff4a6e382"
          }
        },
        "67e04070004b4688a413f73f672ba6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0862e6d64c5046eeba6889937d3aa563",
            "max": 20321280,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b33aa5eadc914f9585110df8861796ab",
            "value": 11466
          }
        },
        "6c7ece8e4ac4461a9341642c969e313a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7083510b063e4d69bf43fbac64a1c916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77ccd734cc3e44f6bc0e2e17d2bb9ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9029ee82df314328a22b647cf40a1bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98dfbaf868e5449e864f8da5d9c86490": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b33aa5eadc914f9585110df8861796ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "badbd4f17b1747878099f242093ef065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14f89939716435f9a5f5532c287d84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98dfbaf868e5449e864f8da5d9c86490",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d080abac50854c979f159667e2806a8b",
            "value": 0
          }
        },
        "cfc8d067c5bb4b21a42fff52d1c8943e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d080abac50854c979f159667e2806a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6eed77f57a64b2eb748976eaa87ea43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_badbd4f17b1747878099f242093ef065",
            "placeholder": "​",
            "style": "IPY_MODEL_6c7ece8e4ac4461a9341642c969e313a",
            "value": " 11465/20321280 [1:39:22&lt;3653:42:01,  1.54it/s]"
          }
        },
        "d71c7e21927c4d4bae8850142bfa57c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfc8d067c5bb4b21a42fff52d1c8943e",
            "placeholder": "​",
            "style": "IPY_MODEL_7083510b063e4d69bf43fbac64a1c916",
            "value": "minibatches:   0%"
          }
        },
        "d87f2ea8b5a149bd8d00007b9bc454ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
